<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Jiang He, 何江, Remote Sensing, Image Processing, Deep Learning, Image Fusion, Spectral Superresolution, Hyperspecral, Wuhan University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/favicon.ico">
<title>Jiang He</title>
</head>

<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/hj.jpg" alt="" height="215px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Jiang He (</font><font size="4"; font style="font-family:Microsoft YaHei">何 江</font><font size="4">)</font></a><br />
<i>Ph.D Candidate </i>
<br /><br />
<a href="http://www.sgg.whu.edu.cn/" target="_blank">School of Geodesy and Geomatics</a><br />
<a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a><br />
<br />
Location: Graduate Computer Room 2-401, School of Geodesy and Geomatics, Luoyu Road #129, Hongshan District, Wuhan, Hubei, China<br />
<class="staffshortcut">
 <A HREF="#News">News</A> | 
 <A HREF="#Interest">Research Interest</A> | 
 <A HREF="#Co-authors">Co-authors</A> |
 <A HREF="#Education">Education</A> | 
 <A HREF="#Publications">Publications</A> | 
 <A HREF="#Projects">Projects</A> | 
 <A HREF="#Services">Services</A> | 
 <A HREF="#Awards">Awards</A>
<br />
<br />
 
Email: jiang_he@whu.edu.cn (hej96.work@gmail.com) <br />
[<a href="https://github.com/JiangHe96" target="_blank">GitHub</a>] 
[<a href="https://scholar.google.com/citations?user=czAEHHoAAAAJ" target="_blank">GoogleScholar</a>] 
[<a href="https://orcid.org/0000-0002-0296-8395" target="_blank">ORCID</a>] 
[<a href="https://www.researchgate.net/profile/Jiang-He-8" target="_blank">ResearchGate</a>] 
[<a href="./Files/hj_wx.jpg" target="_blank">WeChat</a>]
[<a href="./Files/CV.pdf" target="_blank"><font style="font-family:Microsoft YaHei">简历</font></a>]
</td></tr></table>

<A NAME="News"><h2>News</h2></A>
<ul>
<li> <b> <font color="#FF0000">[2023.04]</font> </b> One review is accepted by <b>Information Fusion</b>(<a href= "https://github.com/JiangHe96/DL4sSR" target="_blank">benchmark</a>)!</li>
<li> <b> <font color="#FF0000">[2023.03]</font> </b> Awarded with <b>Special prize of Wang Zhizhuo Innovative Talent</b> (<a href="https://rsgis.whu.edu.cn/info/1080/11295.htm" target="_blank"><font style="font-family:Microsoft YaHei">“王之卓创新人才奖”特等奖</font></a>)!</li>
<li> <b> <font color="#FF0000">[2023.02]</font> </b> One co-author paper is accepted by <b>IEEE GRSL</b>(<a href= "https://ieeexplore.ieee.org/abstract/document/10054245" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.02]</font> </b> One paper is accepted by <b><font style="font-family:Microsoft YaHei">光子学报</font></b>(<a href= "http://www.photon.ac.cn/thesisDetails#10.3788/gzxb20235202.0210002&lang=zh" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.02]</font> </b> Invited as a reporter for <b>IEEE GRSS Wuhan Student Branch Chapter 2023 Academic Report</b>(<a href="./Files/GRSS_Wuhan.png" target="_blank">schedule</a>)!</li>
<li> <b> <font color="#FF0000">[2022.12]</font> </b> Awarded with <b>The Pacemaker to Outstanding Graduate Student</b> (<a href="./Files/yxyjsbb.jpg" target="_blank"><font style="font-family:Microsoft YaHei">优秀研究生标兵</font></a>)!</li>
<li> <b> <font color="#FF0000">[2022.11]</font> </b> The 4th place of Road Damage Detection Challenge <b>(CRDDC2022)</b> organized by <b>IEEE Big Data 2022</b> (<a href="https://crddc2022.sekilab.global/leaderboard/" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2022.10]</font> </b> Awarded with <b>First Prize of Academic Scholarship</b> (<a href="http://gsunion.sgg.whu.edu.cn/notice/1902.html" target="_blank"><font style="font-family:Microsoft YaHei">武汉大学“学业奖学金”一等奖</font></a>)!</li>
<li> <b> <font color="#FF0000">[2022.10]</font> </b> One paper is accepted as a <b>Poster</b> by <b>CITA 2022</b> (<a href="https://b2b.csoe.org.cn/meeting/2022CITA.html" target="_blank">homepage</a>, <a href="./Files/CITA2022_HJ.pdf" target="_blank">poster</a>)!</li>
<li> <b> <font color="#FF0000">[2022.10]</font> </b> Awarded with <b>Graduate INNOVA Excellence Prize</b> (<a href="http://edf.whu.edu.cn/info/1191/2780.htm" target="_blank"><font style="font-family:Microsoft YaHei">研究生英诺卓越奖学金</font></a>)!</li>
<li> <b> <font color="#FF0000">[2022.10]</font> </b> Awarded with <b>Graduate Academic Innovation Outstanding Prize</b> (<a href="https://gs.whu.edu.cn/content.jsp?urltype=news.NewsContentUrl&wbtreeid=1057&wbnewsid=9971" target="_blank"><font style="font-family:Microsoft YaHei">研究生学术创新校长奖</font></a>)!</li>
<li> <b> <font color="#FF0000">[2022.07]</font> </b> One review is accepted by <b><font style="font-family:Microsoft YaHei">测绘学报</font></b>(<a href= "http://xb.sinomaps.com/CN/10.11947/j.AGCS.2022.20220171" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2022.07]</font> </b> One co-author paper is accepted by <b>STOTEN</b>(<a href= "https://www.sciencedirect.com/science/article/pii/S004896972204846X" target="_blank">link</a>, <a href= "https://xy-boy.github.io/" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2022.06]</font> </b> One co-author paper is accepted by <b>IEEE GRSM</b>(<a href= "https://ieeexplore.ieee.org/document/9844267" target="_blank">link</a>, <a href= "https://github.com/liangjiandeng/DLPan-Toolbox" target="_blank">toolbox</a>)!</li>
<li> <b> <font color="#FF0000">[2022.06]</font> </b> One paper is accepted by <b>IEEE TGRS</b>(<a href= "https://doi.org/10.1109/TGRS.2022.3186916" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2022.04]</font> </b> The 8th place of NTIRE 2022 Challenge on Spectral Reconstruction from RGB(<a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Arad_NTIRE_2022_Spectral_Recovery_Challenge_and_Data_Set_CVPRW_2022_paper.html" target="_blank">link</a>, <a href= "https://github.com/JiangHe96/PoNet_plus" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2022.04]</font> </b> One paper is accepted by <b>JAG</b>(<a href= "https://www.sciencedirect.com/science/article/pii/S030324342200099X" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2022.02]</font> </b> One co-author paper is accepted by <b>JAG</b>(<a href= "https://www.sciencedirect.com/science/article/pii/S0303243422000575" target="_blank">link</a>, <a href= "https://github.com/XY-boy/MSTT-STVSR" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2021.12]</font> </b> RgB2CAVE, RGB2CASI, GF2Hyper datasets in <i>PoNet</i><b> (Information Fusion)</b> are released  (<a href="./Files/DataSet_PoNet.html" target="_blank">dataset</a>)!</li>
<li> <b> <font color="#FF0000">[2021.11]</font> </b> OHS data after radiometric calibration in <i>HSRnet</i><b> (IEEE TNNLS)</b> is released  (<a href="https://doi.org/10.5281/zenodo.5642597" target="_blank">dataset</a>)!</li>
<li> <b> <font color="#FF0000">[2021.11]</font> </b> Invited as a reporter for <b>The 6th ZhiZhuo Doctoral Forum of Wuhan University</b> (<a href="./Files/ZhiZhuo2021_ppt.pdf" target="_blank">slides</a>)!</li>
<li> <b> <font color="#FF0000">[2021.11]</font> </b> One paper is accepted by <b>Information Fusion</b>(<a href= "https://www.sciencedirect.com/science/article/pii/S156625352100227X" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2021.01]</font> </b> One paper is accepted by <b>IEEE TNNLS</b> (<a href= "https://ieeexplore.ieee.org/document/9357488" target="_blank">link</a>, <a href= "https://github.com/JiangHe96/HSRnet" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2020.10]</font> </b> Awarded with <b>National Scholarship for Graduate Student</b> (<a href="https://www.whu.edu.cn/info/1118/16651.htm" target="_blank"><font style="font-family:Microsoft YaHei">武汉大学“研究生国家奖学金”</font></a>)!</li>
<li> <b> <font color="#FF0000">[2020.10]</font> </b> Awarded with <b>First Prize of Academic Scholarship</b> (<a href="https://www.gs.whu.edu.cn/info/1057/7261.htm" target="_blank"><font style="font-family:Microsoft YaHei">武汉大学“学业奖学金”一等奖</font></a>)!</li>
<li> <b> <font color="#FF0000">[2020.03]</font> </b> One paper is accepted as an <b>Oral Presentation</b> by <b>IGARSS 2020</b> (<a href="https://www.igarss2020.org/view_paper.php?PaperNum=1646" target="_blank">session</a>, <a href="./Files/IGARSS2020_HJ.pdf" target="_blank">slides</a>)!</li>
</ul>
<br />


 
<A NAME="Interest"><h2>Research Interest</h2></A>
I am working in remote sensing image quality improvement, low-level vision, multi-level version, information fusion and deep learning theory. Currently, I focus on the following research topics:
<ul>
<li>Combined high-level with low-level vision</li>
<li>Combined data-driven with model-driven strategy for low-level vision</li>
<li>Spectral super-resolution in multispectral imaging</li>
<li>Hyperspectral remote sensing image reconstruction</li>
<li>Spatial-spectral-width remote sensing image fusion</li>
<li>Pan-sharpening</li>
</ul>
<br />


<A NAME="Co-authors"><h2>Co-authors</h2></A>
<font size="3"> 
<ul>
<li><a href= "https://liangjiandeng.github.io/" target="_blank"><u>Liang-Jian Deng  (邓良剑)</u></a>, &nbsp;<a href= "https://xy-boy.github.io/" target="_blank"><u>Yi Xiao (肖屹)</u></a> </li>
</ul>
</font>
<br />

 
<A NAME="Education"><h2>Education</h2></A>
<ul>
<li>2021.09-now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pursuing Ph.D in <a href="http://main.sgg.whu.edu.cn/" target="_blank">SGG</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp; Supervisor: Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a> & <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank">Liangpei Zhang</a></li>
<li>2018.09-2021.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; M.E.Candidate in <a href="http://main.sgg.whu.edu.cn/" target="_blank">SGG</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp; Supervisor: Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a> & A.Prof. <a href="http://jli89.users.sgg.whu.edu.cn/" target="_blank">Jie Li</a></li>
<li>2014.09-2018.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.E. in <a href="https://gsee.swjtu.edu.cn/" target="_blank">Faculty of Geosciences and Environmental Engineering</a>, <a href="https://www.swjtu.edu.cn/" target="_blank">Southwest Jiaotong University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </li>
</ul>
<br />

 


<A NAME="Publications"><h2>Publications</h2></A>
<p><b><font size="4"> Journals</b>: </p>
<ul{padding-left: 2em;}>

<p><b><font size="3"> First-authored</b>: </p>
<font size="3"> 
<ul>
<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[8] <b>J. He</b>, Q. Yuan, J. Li, Y. Xiao, D. Liu, H. Shen, and L. Zhang, 
“Spectral super-resolution meets deep learning: achievements and challenges,” 
<i>Information Fusion (<b>INFFUS</b>)</i>, 
in press, 2023. 
(<b>SCI Q1 Top, IF=17.564</b>) 
[<a href= "" target="_blank">Link</a>] 
[<a href= "" target="_blank">PDF</a>] 
[<a href="https://github.com/JiangHe96/DL4sSR" target="_blank">Benchmark</a>]
[<a href="./Files/BibTex.html#hj2023_DL4sSR" target="_blank">BibTex</a>]
</span>
</p> 

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[7] <b>J. He</b>, Q. Yuan, J. Li, and L. Zhang, 
“PoNet: A universal physical optimization-based spectral super-resolution network for arbitrary multispectral images,” 
<i>Information Fusion (<b>INFFUS</b>)</i>, 
vol. 80, pp. 205-225, 2022. 
(<b>SCI Q1 Top, IF=17.564</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S156625352100227X" target="_blank">Link</a>] 
[<a href= "./Files/2022_INFFUS_PoNet.pdf" target="_blank">PDF</a>] 
[<a href="./Files/DataSet_PoNet.html" target="_blank">Dataset</a>]
[<a href="./Files/BibTex.html#hj2022_PoNet" target="_blank">BibTex</a>]
</span>
</p> 

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[6] <b>J. He</b>, Q. Yuan, J. Li, L. Zhang, 
“A Knowledge Optimization-driven Network with Normalizer-Free Group ResNet Prior for Remote Sensing Image Pan-sharpening,” 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>IEEE TGRS</b>)</i>, 
vol. 60, pp. 1-16, 2022, Art no. 5410716. 
(<b>SCI Q1 TOP, IF=8.125</b>) 
[<a href= "https://doi.org/10.1109/TGRS.2022.3186916" target="_blank">Link</a>] 
[<a href="./Files/2022_TGRS_PNXnet.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#hj2022_PNXnet" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[5] <b>J. He</b>, J. Li, Q. Yuan, H. Shen, and L. Zhang, 
“Spectral Response Function-Guided Deep Optimization-Driven Network for Spectral Super-Resolution,” 
<i>IEEE Transactions on Neural Networks and Learning Systems (<b>IEEE TNNLS</b>)</i>, 
vol. 33, no. 9, pp. 4213-4227, 2022. 
(<b>SCI Q1 Top, IF=14.255</b>) 
[<a href= "https://ieeexplore.ieee.org/document/9357488" target="_blank">Link</a>] 
[<a href= "./Files/2021_TNNLS_HSRnet.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/JiangHe96/HSRnet" target="_blank">Code</a>]
[<a href="https://doi.org/10.5281/zenodo.5642597" target="_blank">Dataset</a>]
[<a href="./Files/BibTex.html#hj2021_HSRnet" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[7] <b>J. He</b>, Q. Yuan, J. Li, Y. Xiao, X. Liu, and Y. Zou, 
“DsTer: A dense spectral transformer for remote sensing spectral super-resolution,” 
<i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i>, 
vol. 109, pp. 102773, 2022. 
(<b>SCI Q1 TOP, IF=7.672</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S030324342200099X" target="_blank">Link</a>] 
[<a href="./Files/2022_JAG_DsTer.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#hj2022_DsTer" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[3] <b>J. He</b>, J. Li, Q. Yuan, H. Li, and H. Shen, 
“Spatial-spectral Fusion in Different Swath Widths by a Recurrent Expanding Residual Convolutional Neural Network,” 
<i>Remote Sensing (<b>RS</b>)</i>, 
vol. 11, no. 19, 2203, 2019. 
(<b>SCI Q2, IF=4.848</b>) 
[<a href= "https://www.mdpi.com/2072-4292/11/19/2203" target="_blank">Link</a>] 
[<a href= "./Files/2019_RS_WSSRN.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTex.html#hj2019_WSSRN" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[2] <b>何江</b>, 袁强强, 李杰, 
“面向多光谱卫星成像的广义光谱超分辨率,” 
<i>光子学报</i>, vol. 52, no. 2, pp. 0210002, 2023.
(<b>EI</b>) 
[<a href= "http://www.photon.ac.cn/thesisDetails#10.3788/gzxb20235202.0210002&lang=zh" target="_blank">Link</a>] 
[<a href="./Files/2023_APS_HJ.pdf" target="_blank">PDF</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[1] 张良培, <b>何江</b>, 杨倩倩, 肖屹, 袁强强, 
“数据驱动的多源遥感信息融合研究进展,” 
<i>测绘学报</i>, vol. 51, no. 7, pp. 1317-1337, 2022.
(<b>EI</b>) 
[<a href= "http://xb.sinomaps.com/CN/10.11947/j.AGCS.2022.20220171" target="_blank">Link</a>] 
[<a href="./Files/2022_AGCS_HJ.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTex.html#hj2022_AGCS" target="_blank">BibTex</a>]
</span>
</p>
</ul>

<p><b><font size="3"> Co-authored</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[6] Y. Xiao, Q. Yuan, K. Jiang, <b>J. He</b>, Y. Wang, and L. Zhang,
“From degrade to upgrade: Learning a self-supervised degradation guided adaptive network for blind remote sensing image super-resolution,” 
<i>Information Fusion (<b>INFFUS</b>)</i>, vol. 96, pp. 297–311, 2023.
(<b>SCI Q1 TOP, IF=17.564</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S1566253523001100" target="_blank">Link</a>] 
[<a href="https://github.com/XY-boy/DRSR" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#xiao2023_degrade" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[5] X. Jin, <b>J. He</b>, Y. Xiao and Q. Yuan, 
“Learning a Local-Global Alignment Network for Satellite Video Super-Resolution,” 
<i>IEEE Geoscience and Remote Sensing Letters (<b>IEEE GRSL</b>)</i>, 
in press, 2023. 
(<b>SCI Q2, IF=5.343</b>) 
[<a href= "https://ieeexplore.ieee.org/abstract/document/10054245" target="_blank">Link</a>] 
[<a href="./Files/BibTex.html#jin2023learning" target="_blank">Bibtex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[4] D. Liu, J. Li, Q. Yuan, L. Zheng, <b>J. He</b>, S. Zhao, and Y. Xiao,
“An efficient unfolding network with disentangled spatial-spectral representation for hyperspectral image super-resolution,” 
<i>Information Fusion (<b>INFFUS</b>)</i>, vol. 94, pp. 92–111, 2023.
(<b>SCI Q1 TOP, IF=17.564</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S1566253523000258" target="_blank">Link</a>] 
[<a href="https://github.com/denghong-liu/EUNet" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#liu2023_eunet" target="_blank">BibTex</a>]
</span>
</p>


<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[3] L.-J. Deng, G. Vivone, M. E. Paoletti, G. Scarpa, <b>J. He</b>, Y. Zhang, J. Chanussot, and A. Plaza, 
“Machine Learning in Pansharpening: A Benchmark, From Shallow to Deep Networks,” 
<i>IEEE Geoscience and Remote Sensing Magazine (<b>IEEE GRSM</b>)</i>, 
vol. 10, no. 3, pp. 279-315, 2022.
(<b>SCI Q1 TOP, IF=13.93</b>) 
[<a href= "https://ieeexplore.ieee.org/document/9844267" target="_blank">Link</a>] 
[<a href="./Files/2022_GRSM_HJ.pdf" target="_blank">PDF</a>]
[<a href= "https://github.com/liangjiandeng/DLPan-Toolbox" target="_blank">Toolbox</a>]
[<a href="./Files/BibTex.html#hj2022_GRSM" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[2] Y. Xiao, Q. Yuan, <b>J. He</b>, Q. Zhang, J. Sun, X. Su, J. Wu, and L. Zhang, 
“Space-time super-resolution for satellite video: A joint framework based on multi-scale spatial-temporal transformer,” 
<i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i>, 
vol. 108, pp. 102731, 2022. 
(<b>SCI Q1 TOP, IF=7.672, <font color="#FF0000">ESI Top 1%</font></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0303243422000575" target="_blank">Link</a>] 
[<a href="https://github.com/XY-boy/MSTT-STVSR" target="_blank">Code</a>]
[<a href="./Files/BibTex.html#xy2022_space" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[1] Y. Xiao, Y. Wang, Q. Yuan, <b>J. He</b>,  and L. Zhang,
“Generating a long-term (2003−2020) hourly 0.25° global PM2.5 dataset via spatiotemporal downscaling of CAMS with deep learning (DeepCAMS),” 
<i>Science of The Total Environment (<b>STOTEN</b>)</i>, vol. 848, pp. 157747, 2022. 
(<b>SCI Q2 TOP, IF=10.75</b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S004896972204846X" target="_blank">Link</a>] 
[<a href="./Files/BibTex.html#xy2022_deepcams" target="_blank">BibTex</a>]
</span>
</p>
 
</ul>

</ul>

</font>
<br />

<p><b><font size="4">Conferences</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[4] S. Wang, Y. Tang, X. Liao, <b>J. He</b>, and <i>etal. </i>,
“An Ensemble Learning Approach with Multi-depth Attention Mechanism for Road Damage Detection,”
<i>2022 IEEE International Conference on Big Data
(<b>Big Data</b>)</i>, 
pp. 6439-6444, 2022.
[<a href="https://ieeexplore.ieee.org/abstract/document/10021018" target="_blank">link</a>]
[<a href="./Files/BibTex.html#wang2022ensemble" target="_blank">BibTex</a>]
</span>
</p>
 
<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[3] B. Arad, R. Timofte, … <b>J. He</b>, and <i>etal. </i>,
“NTIRE 2022 Spectral Recovery Challenge and Data Set,”
<i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>)</i>, 
pp. 863-881, 2022.
(<b>NTIRE2022, <font color="#FF0000">The 8 th Place</font></b>) 
[<a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Arad_NTIRE_2022_Spectral_Recovery_Challenge_and_Data_Set_CVPRW_2022_paper.html" target="_blank">link</a>]
[<a href= "https://github.com/JiangHe96/PoNet_plus" target="_blank">code</a>]
[<a href="./Files/NTIRE2022_HJ.pdf" target="_blank">pdf</a>]
[<a href="./Files/BibTex.html#hj2022_NTIRE" target="_blank">BibTex</a>]
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[2] 
J. Gao, J. Li, Q. Yuan, <b>J. He</b>, and X. Su,
“Self-supervised Hyperspectral and Multispectral Image Fusion in Deep Neural Network,”
<i>International Conference on Image and Graphics (<b>ICIG</b>)</i>, 
pp. 425-436, 2021. 
</span>
</p>

<p style="text-indent: -1.6rem;margin-left: 0rem;text-align: justify;">
<span>[1] <b>J. He</b>, J. Li and Q. Yuan, 
“Data-Driven and Model-Driven Spectral Superresolution Algorithms: Combination, Analysis and Application for Classification,” 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Hawaii, USA, pp. 2667-2670, 2020. 
(<b>EI, <font color="#FF0000">Oral</font></b>) 
[<a href="./Files/IGARSS2020_HJ.pdf" target="_blank">Slides</a>]
</span>
</p>

</ul>
<br />
 
 
 
 

<A NAME="Projects"><h2>Projects</h2></A>
<font size="3"> 
<ul>
<li><a href= "https://github.com/liangjiandeng/DLPan-Toolbox" target="_blank">DLPan-Toolbox</a>, <a href= "https://liangjiandeng.github.io/PanCollection.html" target="_blank">PanCollection</a> for <b>IEEE GRSM</b></li>
</ul>
</font>
<br />




 
<A NAME="Services"><h2>Services</h2></A>


<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>China Society of Images and Graphics, Student Member, 2021-Now</li>
</ul>
</font>
<br />
<br />
<br />
 
<p><b>Journal Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>Information Fusion (<b>INFFUS</b>)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</li>
<li>ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>)</li>
<li>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</li>
<li>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>J-STARS</b>)</li>
<li>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</li>
<li>Computer Methods and Programs in Biomedicine (<b>CMPB</b>)</li>
<li>Computational Intelligence and Neuroscience (<b>CIN</b>)</li>
<li>IEEE Access</li>
<li>Journal of Sensors</li>
</ul>
</font>
<br />


<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2022, Special Prize of Wang Zhizhuo Innovative Talent, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学“王之卓创新人才”特等奖</font></li>
<li>2022, The Pacemaker to Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生标兵</font></li>
<li>2022, Graduate INNOVA Excellence Prize, Wuhan University | <font style="font-family:Microsoft YaHei">研究生英诺卓越奖学金</font></li>
<li>2022, Graduate Academic Innovation Outstanding Prize, Wuhan University | <font style="font-family:Microsoft YaHei">研究生学术创新校长奖</font></li>
<li>2022, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">学业奖学金一等奖</font></li>
<li>2020, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">学业奖学金一等奖</font></li>
<li>2020, National Scholarship for Graduate Student, Ministry of Education | <font style="font-family:Microsoft YaHei">研究生国家奖学金</font></li>
<li>2020, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生</font></li>
<li>2019, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">学业奖学金一等奖</font></li>
<li>2018, Outstanding Undergraduate, Southwest Jiaotong University | <font style="font-family:Microsoft YaHei">西南交通大学优秀本科毕业生</font></li>
<li>2016, Second Prize of The National College Students of Surveying and Mapping Skills Contest, Ministry of Natrual Resources | <font style="font-family:Microsoft YaHei">全国高等学校大学生测绘技能大赛二等奖</font></li>

</ul>
</font>
 
<br />
<br />


<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5784p0sxc3k&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>


<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


<!--
All Rights Reserved by Jiang He. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

<!--
<font size="2"; color="#A0A0A0";>
<p style="text-align:center">Updating time: 2021.08.16</p>
</font>
-->

</body>
</html>
